{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/20 - in progress of recreating this project here from my \"rough\" version that's complete, but quite messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project came from me reading about \"all-time high\" short ratios for SPY, the S&P 500 Index ETF. The article positioned this as an ominous sign, but it made me wonder:\n",
    "\n",
    "\"What tends to happen to future returns when a stock (or ETF) has a high (or low) short ratio?\"\n",
    "\n",
    "On the one hand, a high short ratio suggests a high level of negative sentiment towards that holding. But, on the other, shorts have to close out their positions at some point, so a high short ratio could also portend future demand, which could be a positive.\n",
    "\n",
    "I thought this would be a great question to explore personally - and a great way to develop my data scraping/pandas manipulation skills.\n",
    "\n",
    "My goal is to look at the stocks in the S&P 500 and observe any potential relationship(s) between short interest and future returns.\n",
    "\n",
    "NOTES:\n",
    "- I could not find a publicly available \"short ratio\" data set, so I used a proxy based on daily short volume of trading. Namely, I used the trailing 30 day average of short volume as a percentage of total trading volume. To improve the accuracy of this analysis it could be beneficial to access a data set specifically looking at short shares outstanding, not just daily volume of trading.\n",
    "- I still am learing the very basics of machine learning and other forms of predictive analysis, so right now this is really just an exercise in data gathering and manipulation. But that would be a great next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape a list of the S&P 500 companies and their ticker symbols from Wikipedia\n",
    "\n",
    "# Imports\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Open the url request and save \n",
    "page = urllib.request.urlopen(url)\n",
    "\n",
    "# Parse the HTML into BeautifulSoup\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "# Create a variable to hold the HTML for the table in question (that holds the S&P 500 stocks and tickers)\n",
    "# From exploring the HTML of the page I found that the table in question was a class 'wikitable sortable'\n",
    "ticker_table = soup.find('table', class_='wikitable sortable')\n",
    "\n",
    "# Initialize lists to \"catch\" the tickers and company names\n",
    "tickers = []\n",
    "companies = []\n",
    "\n",
    "# Loop through my table rows and extract the first two cells of each row (which correspond to 'ticker' and 'company')\n",
    "for row in ticker_table.find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    count = 1\n",
    "    for cell in cells:\n",
    "        if count == 1:\n",
    "            tickers.append(cell.find('a', href=True).string)\n",
    "            count += 1\n",
    "        elif count == 2:\n",
    "            companies.append(cell.string)\n",
    "            count += 2\n",
    "        else:\n",
    "            count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['3M Company',\n",
       " 'Abbott Laboratories',\n",
       " 'AbbVie Inc.',\n",
       " 'ABIOMED Inc',\n",
       " 'Accenture plc']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check my lists\n",
    "display(tickers[0:5])\n",
    "display(len(tickers))\n",
    "display(companies[0:5])\n",
    "display(len(companies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists look right, but we have 505 comapanies/tickers, NOT 500. Looks like it could be an error, but actually the S&P 500 name is slightly misleading. \n",
    "\n",
    "The \"500\" refers to the number of companies in the index. There are actually 505 different securities listed on the index. Some companies have multiple securities listed - for example: Berkshire Hathaway has both 'A' and 'B' shares listed.\n",
    "\n",
    "This means our list lengths look good. We can consider this step a success and move on.\n",
    "\n",
    "Ultimately, all of this data will be stored in a dataframe, so let's set that up now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker              company\n",
      "0    MMM           3M Company\n",
      "1    ABT  Abbott Laboratories\n",
      "2   ABBV          AbbVie Inc.\n",
      "3   ABMD          ABIOMED Inc\n",
      "4    ACN        Accenture plc\n"
     ]
    }
   ],
   "source": [
    "# Import pandas and iniatilize dataframe for final data\n",
    "import pandas as pd\n",
    "final_df = pd.DataFrame(tickers, columns=['ticker'])\n",
    "final_df['company'] = companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
